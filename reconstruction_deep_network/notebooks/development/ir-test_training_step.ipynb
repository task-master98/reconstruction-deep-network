{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test Training Step**\n",
    "This notebook will be used to test the training step function in the `ModelTrainer` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from torchvision import transforms\n",
    "\n",
    "import reconstruction_deep_network\n",
    "from reconstruction_deep_network.data_loader.custom_loader import CustomDataLoader\n",
    "from reconstruction_deep_network.trainer.trainer import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_dir = reconstruction_deep_network.__path__[0]\n",
    "root_dir = os.path.dirname(module_dir)\n",
    "data_dir = os.path.join(root_dir, \"data\", \"v1\")\n",
    "embedding_dir = os.path.join(data_dir, \"text_embeddings\")\n",
    "img_encoding_dir = os.path.join(data_dir, \"image_latents\")\n",
    "if not os.path.isdir(img_encoding_dir):\n",
    "    os.makedirs(img_encoding_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_encoding(scan_id: str, img_name: str):\n",
    "    file_name = os.path.join(embedding_dir, scan_id, f\"{img_name}.npz\")\n",
    "    np_tensor = np.load(file_name, allow_pickle=True)\n",
    "    embedding_vec = []\n",
    "    for key in np_tensor.files:\n",
    "        data_dict = np_tensor[key].item()\n",
    "        embeddings = torch.from_numpy(data_dict[\"embeddings_1\"])\n",
    "        embedding_vec.append(embeddings)\n",
    "    \n",
    "    return torch.stack(embedding_vec, dim=1)\n",
    "\n",
    "def load_img_encoding(scan_id: str, img_name: str):\n",
    "    file_name = os.path.join(img_encoding_dir, scan_id, f\"{img_name}.npz\")\n",
    "    np_tensor = np.load(file_name)[\"latent\"]\n",
    "    return np_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan_id = \"17DRP5sb8fy\"\n",
    "# img_name = \"00ebbf3782c64d74aaf7dd39cd561175\"\n",
    "# embedding_vec = load_text_encoding(scan_id, img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan_id = \"17DRP5sb8fy\"\n",
    "# img_name = \"00ebbf3782c64d74aaf7dd39cd561175\"\n",
    "# latents = load_img_encoding(scan_id, img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = ModelTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataLoader()\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                    dataset,\n",
    "                    batch_size = 4,\n",
    "                    shuffle = False,\n",
    "                    num_workers = 0,\n",
    "                    drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_loader:\n",
    "#     loss = model_trainer.training_step(batch)\n",
    "#     print(loss)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test Inference Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "                    dataset,\n",
    "                    batch_size = 1,\n",
    "                    shuffle = False,\n",
    "                    num_workers = 0,\n",
    "                    drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in val_loader:\n",
    "    loss = model_trainer.validation_step(batch, 0)\n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = loss.squeeze()\n",
    "# combs = list(itertools.product(range(2), range(4)))\n",
    "\n",
    "# fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(12, 5))\n",
    "# for itr, comb in enumerate(combs):\n",
    "#     axs[comb].imshow(images[itr])\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(299),\n",
    "        transforms.CenterCrop(299),                 \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n",
    ")\n",
    "\n",
    "x_inp = preprocess(torch.randn(8, 3, 512, 512)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reconstruction-deep-network-Kqq14QZk-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
