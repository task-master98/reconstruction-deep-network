{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Image Correspondence**\n",
    "This notebook will be used to build the pipeline and experiment with image correspondence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, truncnorm, t, cauchy\n",
    "from scipy.special import kl_div\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import os\n",
    "\n",
    "from reconstruction_deep_network.preprocessing.feature_points import FeaturePointDetector, VisualizeCorners\n",
    "from reconstruction_deep_network.preprocessing.optical_flow import FeatureMatching, MatchVisualizer\n",
    "from reconstruction_deep_network.data_loader.matterport import MatterPortData\n",
    "\n",
    "import reconstruction_deep_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_dir = reconstruction_deep_network.__path__[0]\n",
    "results_dir = os.path.join(module_dir, \"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize dataset\n",
    "scan_hash = \"17DRP5sb8fy\"\n",
    "panorama_id = \"0f37bd0737e349de9d536263a4bdd60d\"\n",
    "data_loader = MatterPortData(scan_hash)\n",
    "\n",
    "color_image_1 = data_loader.load_color_image(panorama_id, 1, 4)\n",
    "color_image_2 = data_loader.load_color_image(panorama_id, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## detect feature points\n",
    "feature_point_det = FeaturePointDetector(2000)\n",
    "kp_1, des_1 = feature_point_det.sift_corners(color_image_1)\n",
    "kp_2, des_2 = feature_point_det.sift_corners(color_image_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize features\n",
    "feature_vis = VisualizeCorners()\n",
    "kp_image_1 = feature_vis.visualize_keypoints(color_image_1, kp_1)\n",
    "kp_image_2 = feature_vis.visualize_keypoints(color_image_2, kp_2)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 10))\n",
    "axs[0].imshow(kp_image_1)\n",
    "axs[1].imshow(kp_image_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## match features\n",
    "ratios = np.linspace(0.3, 0.7, 5)\n",
    "feature_match = FeatureMatching()\n",
    "feature_match_dict = {}\n",
    "for ratio in ratios:\n",
    "    matches, mask = feature_match.flann_matching(des_1, des_2, \"sift\", ratio)\n",
    "    feature_match_dict[f\"{ratio}\"] = (matches, mask)\n",
    "\n",
    "## visualize feature matches\n",
    "match_visualizer = MatchVisualizer()\n",
    "\n",
    "for ratio in feature_match_dict:\n",
    "    matches, mask = feature_match_dict[ratio]\n",
    "    img = match_visualizer.visualize_matches(color_image_1, color_image_2, kp_1, kp_2, matches, mask)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Ratio: {ratio}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Matches Between Distinct Images**\n",
    "This is to investigate if matches are still provided for distinct images, using a ratio threshold of 0.5 from the previous result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_loader.load_color_image(panorama_id, 1, 0)\n",
    "test_kp, test_des = feature_point_det.sift_corners(test_image)\n",
    "\n",
    "test_match, test_mask = feature_match.flann_matching(des_1, test_des, \"sift\", 0.5)\n",
    "test_img = match_visualizer.visualize_matches(color_image_1, test_image, kp_1, test_kp, test_match, test_mask)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(test_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_match, test_mask = feature_match.flann_matching(des_2, test_des, \"sift\", 0.5)\n",
    "test_img = match_visualizer.visualize_matches(color_image_2, test_image, kp_2, test_kp, test_match, test_mask)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(test_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: If two images are distinct then with the ratio test, we can eliminate any false positives. We can track the match count from the pair of images and look for similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Points in Empty Images**\n",
    "This will be used to inspect feature points in plane surface images. Hypothesis: there should not be many feature points in empty surface images. Example: walls, ceilings etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_image = data_loader.load_color_image(panorama_id, 1, 1)\n",
    "empty_kp, empty_des = feature_point_det.sift_corners(empty_image)\n",
    "\n",
    "enpty_kp_img = feature_vis.visualize_keypoints(empty_image, empty_kp)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(enpty_kp_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Utility Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_based_segmentation(img: np.ndarray):\n",
    "    lab_image = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    lower_range = np.array([150, 128, 128])\n",
    "    upper_range = np.array([200, 128, 128])\n",
    "\n",
    "    mask = cv2.inRange(lab_image, lower_range, upper_range)\n",
    "\n",
    "    result = cv2.bitwise_and(img, img, mask=mask)\n",
    "    return result\n",
    "\n",
    "def edge_detection(img: np.ndarray):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray_img, threshold1=100, threshold2=200)\n",
    "    return edges\n",
    "\n",
    "def blob_detection(img: np.ndarray):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    log_image = cv2.Laplacian(gray_img, cv2.CV_64F)\n",
    "    log_image = cv2.convertScaleAbs(log_image)\n",
    "\n",
    "    _, binary_image = cv2.threshold(log_image, 30, 255, cv2.THRESH_BINARY)\n",
    "    return binary_image\n",
    "\n",
    "def histogram_analysis(img: np.ndarray):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    histogram = cv2.calcHist([gray_img], [0], None, [256], [0, 256])\n",
    "    histogram = histogram.squeeze()\n",
    "    normalized_hist = ((histogram - np.min(histogram)) / (np.max(histogram) - np.min(histogram)))\n",
    "    variance = np.var(normalized_hist)\n",
    "    return normalized_hist, variance\n",
    "\n",
    "def model_normal_dist(histogram: np.ndarray):\n",
    "    x_mean = np.sum(np.arange(len(histogram)) * histogram) / np.sum(histogram)\n",
    "    std_dev = np.std(histogram)\n",
    "    x = np.linspace(0, 256, len(histogram))\n",
    "    pdf_normal = norm.pdf(x, loc=x_mean, scale=std_dev)\n",
    "    pdf_normal = np.clip(pdf_normal, 0, 256)\n",
    "    pdf_normal /= np.sum(pdf_normal)\n",
    "    return pdf_normal\n",
    "\n",
    "def get_truncated_normal(histogram: np.ndarray):\n",
    "    mean = np.sum(np.arange(len(histogram)) * histogram) / np.sum(histogram)\n",
    "    low, upp = 0, 256\n",
    "    sd = 1\n",
    "    return truncnorm(\n",
    "        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
    "\n",
    "def model_cauchy_distribution(histogram: np.ndarray):\n",
    "    x_mean = np.sum(np.arange(len(histogram)) * histogram) / np.sum(histogram)\n",
    "    scale_parameter = 20  # You can adjust this value\n",
    "    x = np.linspace(0, 256, len(histogram))\n",
    "    pdf_cauchy = cauchy.pdf(x, loc=x_mean, scale=scale_parameter)    \n",
    "\n",
    "    # Calculate the PDF of the Student's t-distribution\n",
    "    pdf_cauchy = np.clip(pdf_cauchy, 0, 256)\n",
    "    pdf_cauchy /= np.sum(pdf_cauchy)\n",
    "    return pdf_cauchy\n",
    "\n",
    "def detect_and_draw_lines(raw_image, threshold1=50, threshold2=200, hough_threshold=100):\n",
    "\n",
    "    image = raw_image.copy()\n",
    "        \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(gray, None, threshold1, threshold2)\n",
    "    \n",
    "    # Use the Hough Line Transform to detect lines\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 150, None, 0, 0)\n",
    "    \n",
    "    line_centers = []\n",
    "    line_angles_u = []\n",
    "    line_angles_v = []\n",
    "\n",
    "    if lines is not None:\n",
    "        # Draw detected lines on the original image\n",
    "        for i in range(len(lines)):\n",
    "            # rho, theta = line[0]\n",
    "            # a = np.cos(theta)\n",
    "            # b = np.sin(theta)\n",
    "            # x0 = a * rho\n",
    "            # y0 = b * rho\n",
    "            # x1 = int(x0 + 1000 * (-b))\n",
    "            # y1 = int(y0 + 1000 * (a))\n",
    "            # x2 = int(x0 - 1000 * (-b))\n",
    "            # y2 = int(y0 - 1000 * (a))\n",
    "            l = lines[i][0]\n",
    "            x_center = (l[0] + l[2] )/ 2\n",
    "            y_center = (l[1] + l[3]) / 2\n",
    "            u = abs(l[2] - l[0])\n",
    "            v = abs(l[3] - l[1])\n",
    "\n",
    "            line_centers.append([x_center, y_center])\n",
    "            line_angles_u.append(u)\n",
    "            line_angles_v.append(v)\n",
    "            image = cv2.line(image, (l[0], l[1]), (l[2], l[3]), (0,0,255), 3)\n",
    "            \n",
    "    \n",
    "    return image, np.array(line_centers), np.array(line_angles_u), np.array(line_angles_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## histogram analysis\n",
    "hist, variance = histogram_analysis(empty_image)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot the image on the left subplot\n",
    "ax2.set_title('Image')\n",
    "ax2.imshow(empty_image)\n",
    "ax2.axis('off')\n",
    "\n",
    "# Plot the histogram on the right subplot\n",
    "ax1.set_title(f'Histogram, variance: {variance}')\n",
    "ax1.set_xlabel('Pixel Intensity')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.bar(np.arange(256), hist, color='gray')\n",
    "ax1.set_xlim([0, 256])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## histogram analysis\n",
    "hist_texture, variance_texture = histogram_analysis(color_image_1)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot the image on the left subplot\n",
    "ax2.set_title('Image')\n",
    "ax2.imshow(color_image_1)\n",
    "ax2.axis('off')\n",
    "\n",
    "# Plot the histogram on the right subplot\n",
    "ax1.set_title(f'Histogram, variance: {variance_texture}')\n",
    "ax1.set_xlabel('Pixel Intensity')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.bar(np.arange(256), hist_texture, color='gray')\n",
    "ax1.set_xlim([0, 256])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: the variance of the histograms might not be enough to differentiate between the textureless image and an image with lot of textures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model normal distribution\n",
    "hist_norm_textureless = model_cauchy_distribution(hist)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot the histogram on the right subplot\n",
    "ax1.set_title(f'Histogram: Normal')\n",
    "ax1.set_xlabel('Pixel Intensity')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.bar(np.arange(256), hist_norm_textureless, color='gray')\n",
    "ax1.set_xlim([0, 256])\n",
    "\n",
    "# Plot the histogram on the right subplot\n",
    "ax2.set_title(f'Histogram: Textureless')\n",
    "ax2.set_xlabel('Pixel Intensity')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.bar(np.arange(256), hist, color='gray')\n",
    "ax2.set_xlim([0, 256])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-5\n",
    "divergence = np.sum(kl_div(hist_norm_textureless + epsilon, hist + epsilon))\n",
    "divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_norm_texture = model_cauchy_distribution(hist_texture)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot the histogram on the right subplot\n",
    "ax1.set_title(f'Histogram: Normal')\n",
    "ax1.set_xlabel('Pixel Intensity')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.bar(np.arange(256), hist_norm_texture, color='gray')\n",
    "ax1.set_xlim([0, 256])\n",
    "\n",
    "# Plot the histogram on the right subplot\n",
    "ax2.set_title(f'Histogram: Texture')\n",
    "ax2.set_xlabel('Pixel Intensity')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.bar(np.arange(256), hist_texture, color='gray')\n",
    "ax2.set_xlim([0, 256])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divergence = np.sum(kl_div(hist_norm_texture + epsilon, hist_texture + epsilon))\n",
    "divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_image_3 = data_loader.load_color_image(panorama_id, 0, 1)\n",
    "## histogram analysis\n",
    "hist_3, variance_3 = histogram_analysis(color_image_3)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot the image on the left subplot\n",
    "ax2.set_title('Image')\n",
    "ax2.imshow(color_image_3)\n",
    "ax2.axis('off')\n",
    "\n",
    "# Plot the histogram on the right subplot\n",
    "ax1.set_title(f'Histogram, variance: {variance_3}')\n",
    "ax1.set_xlabel('Pixel Intensity')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.bar(np.arange(256), hist_3, color='gray')\n",
    "ax1.set_xlim([0, 256])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Identifying the modes of the distribution should be the way ahead. If there is at least one more mode, we can surely say that the image might have different textures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_1 = find_peaks(hist, height=0.3, width=2)\n",
    "peaks_2 = find_peaks(hist_texture, height=0.3, width=2)\n",
    "peaks_3 = find_peaks(hist_3, height=0.3, width=2)\n",
    "\n",
    "x = np.arange(0, 256)\n",
    "\n",
    "peak_locations_1 = [x[i] for i in peaks_1[0]]\n",
    "peak_locations_2 = [x[i] for i in peaks_2[0]]\n",
    "peak_locations_3 = [x[i] for i in peaks_3[0]]\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12, 10))\n",
    "\n",
    "axs[0].bar(np.arange(256), hist, color='gray')\n",
    "axs[0].set_xlim([0, 256])\n",
    "\n",
    "axs[0].scatter(x = peak_locations_1, y = hist[peak_locations_1], color = 'r')\n",
    "axs[0].set_title(\"Textureless\")\n",
    "\n",
    "axs[1].bar(np.arange(256), hist_texture, color='gray')\n",
    "axs[1].set_xlim([0, 256])\n",
    "axs[1].scatter(x = peak_locations_2, y = hist_texture[peak_locations_2], color = 'r')\n",
    "axs[1].set_title(\"Texture\")\n",
    "\n",
    "axs[2].bar(np.arange(256), hist_3, color='gray')\n",
    "axs[2].set_xlim([0, 256])\n",
    "axs[2].scatter(x = peak_locations_3, y = hist_3[peak_locations_3], color = 'r')\n",
    "axs[2].set_title(\"Intermediate\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Blob Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = blob_detection(empty_image)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].imshow(blob)\n",
    "axs[0].set_title(\"Blob\")\n",
    "\n",
    "axs[1].imshow(empty_image)\n",
    "axs[1].set_title(\"Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Line Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_image, linecenters, U, V = detect_and_draw_lines(empty_image, 100, 200)\n",
    "print(f\"Number of Lines: {len(linecenters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "axs[0].imshow(line_image)\n",
    "axs[0].set_title(\"Blob\")\n",
    "\n",
    "axs[1].imshow(empty_image)\n",
    "axs[1].set_title(\"Image\")\n",
    "\n",
    "axs[2].quiver(linecenters[:, 0], linecenters[:, 1], U, V, angles='xy', scale_units='xy', scale=1)\n",
    "axs[2].set_title(\"Center Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lines in an image with texture\n",
    "line_texture_image, linecenters, U, V = detect_and_draw_lines(color_image_1, 100, 200)\n",
    "print(f\"Number of Lines: {len(linecenters)}\")\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "axs[0].imshow(line_texture_image)\n",
    "axs[0].set_title(\"Blob\")\n",
    "\n",
    "axs[1].imshow(color_image_1)\n",
    "axs[1].set_title(\"Image\")\n",
    "\n",
    "axs[2].quiver(linecenters[:, 0], linecenters[:, 1], U, V, angles='xy', scale_units='xy', scale=1)\n",
    "axs[2].set_title(\"Center Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lines in an image with texture\n",
    "line_texture_image, linecenters, U, V = detect_and_draw_lines(color_image_2, 100, 200)\n",
    "print(f\"Number of Lines: {len(linecenters)}\")\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "axs[0].imshow(line_texture_image)\n",
    "axs[0].set_title(\"Blob\")\n",
    "\n",
    "axs[1].imshow(color_image_2)\n",
    "axs[1].set_title(\"Image\")\n",
    "\n",
    "axs[2].quiver(linecenters[:, 0], linecenters[:, 1], U, V, angles='xy', scale_units='xy', scale=1)\n",
    "axs[2].set_title(\"Center Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reconstruction-deep-network-Kqq14QZk-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
