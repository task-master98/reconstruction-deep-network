{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Recognizing Textureless Images**\n",
    "This notebook will be used to create a metadata file to pinpoint textureless images from the previous results. The output will be a csv file that can be used to discard the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from scipy.signal import find_peaks, hilbert\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import cauchy\n",
    "from scipy.special import kl_div\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "import reconstruction_deep_network\n",
    "from reconstruction_deep_network.preprocessing.feature_points import FeaturePointDetector\n",
    "from reconstruction_deep_network.preprocessing.optical_flow import FeatureMatching\n",
    "from reconstruction_deep_network.data_loader.matterport import MatterPortData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_dir = reconstruction_deep_network.__path__[0]\n",
    "root_dir = os.path.dirname(module_dir)\n",
    "result_dir = os.path.join(module_dir, \"results\")\n",
    "data_dir = os.path.join(root_dir, \"data\", \"v1\", \"scans\")\n",
    "color_images = os.path.join(data_dir, \"17DRP5sb8fy\", \"matterport_color_images\")\n",
    "metadata_dir = os.path.join(module_dir, \"metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_analysis(img: np.ndarray):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    histogram = cv2.calcHist([gray_img], [0], None, [256], [0, 256])\n",
    "    histogram = histogram.squeeze()\n",
    "    normalized_hist = ((histogram - np.min(histogram)) / (np.max(histogram) - np.min(histogram)))\n",
    "    variance = np.var(normalized_hist)\n",
    "    return normalized_hist\n",
    "\n",
    "def count_peaks(histogram: np.ndarray):\n",
    "    peaks = find_peaks(histogram, width=2)\n",
    "    peak_indices = peaks[0]\n",
    "    return peak_indices\n",
    "\n",
    "def model_cauchy_distribution(histogram: np.ndarray):\n",
    "    x_mean = np.sum(np.arange(len(histogram)) * histogram) / np.sum(histogram)\n",
    "    scale_parameter = 20  # You can adjust this value\n",
    "    x = np.linspace(0, 256, len(histogram))\n",
    "    pdf_cauchy = cauchy.pdf(x, loc=x_mean, scale=scale_parameter)    \n",
    "\n",
    "    # Calculate the PDF of the Student's t-distribution\n",
    "    pdf_cauchy = np.clip(pdf_cauchy, 0, 256)\n",
    "    pdf_cauchy /= np.sum(pdf_cauchy)\n",
    "    return pdf_cauchy\n",
    "\n",
    "def compute_kl_divergence(hist_simulated, hist):\n",
    "    epsilon = 1e-5\n",
    "    divergence = np.sum(kl_div(hist_simulated + epsilon, hist + epsilon))\n",
    "    return divergence\n",
    "\n",
    "def compute_envelope(x_signal: np.ndarray):\n",
    "    x_hilbert = hilbert(x_signal)\n",
    "    envelope = np.abs(x_hilbert)\n",
    "    return envelope\n",
    "\n",
    "def hl_envelopes_idx(s, dmin=1, dmax=1, split=False):\n",
    "    \"\"\"\n",
    "    Input :\n",
    "    s: 1d-array, data signal from which to extract high and low envelopes\n",
    "    dmin, dmax: int, optional, size of chunks, use this if the size of the input signal is too big\n",
    "    split: bool, optional, if True, split the signal in half along its mean, might help to generate the envelope in some cases\n",
    "    Output :\n",
    "    lmin,lmax : high/low envelope idx of input signal s\n",
    "    \"\"\"\n",
    "\n",
    "    # locals min      \n",
    "    lmin = (np.diff(np.sign(np.diff(s))) > 0).nonzero()[0] + 1 \n",
    "    # locals max\n",
    "    lmax = (np.diff(np.sign(np.diff(s))) < 0).nonzero()[0] + 1 \n",
    "    \n",
    "    if split:\n",
    "        # s_mid is zero if s centered around x-axis or more generally mean of signal\n",
    "        s_mid = np.mean(s) \n",
    "        # pre-sorting of locals min based on relative position with respect to s_mid \n",
    "        lmin = lmin[s[lmin]<s_mid]\n",
    "        # pre-sorting of local max based on relative position with respect to s_mid \n",
    "        lmax = lmax[s[lmax]>s_mid]\n",
    "\n",
    "    # global min of dmin-chunks of locals min \n",
    "    lmin = lmin[[i+np.argmin(s[lmin[i:i+dmin]]) for i in range(0,len(lmin),dmin)]]\n",
    "    # global max of dmax-chunks of locals max \n",
    "    lmax = lmax[[i+np.argmax(s[lmax[i:i+dmax]]) for i in range(0,len(lmax),dmax)]]\n",
    "    \n",
    "    return lmin,lmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = MatterPortData(\"17DRP5sb8fy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = os.listdir(color_images)\n",
    "color_images = list(filter(lambda x: x.split(\".\")[-1] == \"jpg\", all_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_metadata_df = pd.DataFrame()\n",
    "\n",
    "for file_name in tqdm((color_images)):\n",
    "\n",
    "    img_name = file_name.split(\".\")[0]\n",
    "\n",
    "    panorama_id, cam_index, yaw_index = img_name.split(\"_\")\n",
    "    cam_index = cam_index[1:]\n",
    "\n",
    "    color_image = data_loader.load_color_image(panorama_id, int(cam_index), int(yaw_index))\n",
    "\n",
    "    pixel_hist = histogram_analysis(color_image)\n",
    "\n",
    "    peak_indices = count_peaks(pixel_hist)\n",
    "\n",
    "    simulated_hist = model_cauchy_distribution(pixel_hist)\n",
    "\n",
    "    divergence = compute_kl_divergence(simulated_hist, pixel_hist)\n",
    "\n",
    "    metadata_dict = {\"panorama_id\": panorama_id,\n",
    "                     \"cam_index\": cam_index,\n",
    "                     \"yaw_index\": yaw_index,\n",
    "                     \"histogram_peaks\": len(peak_indices),\n",
    "                     \"kl_divergence\": divergence,\n",
    "                     }\n",
    "    \n",
    "\n",
    "    feature_metadata_df = pd.concat([feature_metadata_df, pd.DataFrame([metadata_dict])], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Verification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## distribution of number of peaks\n",
    "fig = px.box(feature_metadata_df, y = [\"histogram_peaks\", \"kl_divergence\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation between features\n",
    "fig = px.scatter(feature_metadata_df, x = \"kl_divergence\", y = \"histogram_peaks\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_metatada = os.path.join(metadata_dir, \"metadata_final2.csv\")\n",
    "category_metatada_df = pd.read_csv(category_metatada)\n",
    "column_names = list(category_metatada_df.columns)\n",
    "category_metatada_df[\"total_prob\"] = category_metatada_df[column_names[1:]].sum(axis=1)\n",
    "category_metatada_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Merge Metadata Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_metatada_df[\"panorama_id\"] = category_metatada_df[\"panaromic_id\"].apply(lambda x: x.split(\".\")[0].split(\"_\")[0])\n",
    "category_metatada_df[\"cam_index\"] = category_metatada_df[\"panaromic_id\"].apply(lambda x: (x.split(\".\")[0].split(\"_\")[1][-1]))\n",
    "category_metatada_df[\"yaw_index\"] = category_metatada_df[\"panaromic_id\"].apply(lambda x: x.split(\".\")[0].split(\"_\")[-1])\n",
    "category_metatada_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = feature_metadata_df.merge(category_metatada_df, how='inner', on=['panorama_id', 'cam_index', 'yaw_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(\"panaromic_id\", axis=1)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"object_detected\"] = merged_df[\"total_prob\"].apply(lambda x: \"no_object\" if x == 0 else \"object\")\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(merged_df, x = \"object_detected\", y = \"histogram_peaks\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(merged_df, x = \"object_detected\", y = \"kl_divergence\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The object detection method has not exactly helped since the true positive rate is quite high for the prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Testing Hypothesis 1**\n",
    "Hypothesis: If the number of histogram peaks is greater than a threshold we can safely say that the image is not textureless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "threshold = 5\n",
    "\n",
    "def change_object_class_based_on_hist(row):\n",
    "    if row[\"total_prob\"] == 0:\n",
    "        if row[\"histogram_peaks\"] > threshold:\n",
    "            return \"object\"\n",
    "        else:\n",
    "            return \"no_object\"\n",
    "    \n",
    "    return \"object\"\n",
    "\n",
    "merged_df[\"object_detected\"] = merged_df.apply(change_object_class_based_on_hist, axis=1)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(merged_df, x = \"object_detected\", y = \"histogram_peaks\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(merged_df.loc[merged_df[\"object_detected\"] == \"no_object\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_object_df = merged_df.loc[merged_df[\"object_detected\"] == \"no_object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(os.path.join(result_dir, \"no_objects\")):\n",
    "    os.makedirs(os.path.join(result_dir, \"no_objects\"))\n",
    "\n",
    "for idx, row in tqdm(no_object_df.iterrows()):\n",
    "    panorama_id, cam_index, yaw_index = row[\"panorama_id\"], row[\"cam_index\"], row[\"yaw_index\"]\n",
    "    file_name = f\"{panorama_id}_i{cam_index}_{yaw_index}.jpg\"\n",
    "\n",
    "    file_prefix_path = os.path.join(color_images, file_name)\n",
    "    image = Image.open(file_prefix_path)\n",
    "\n",
    "    updated_path = os.path.join(result_dir, \"no_objects\", file_name)\n",
    "    image = image.save(updated_path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_object_df[no_object_df[\"panorama_id\"] == \"194bef4cbba641dc9860ba7f43a0c16a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.violin(no_object_df, y=\"kl_divergence\", box=True, # draw box plot inside the violin\n",
    "                points='all', # can be 'outliers', or False\n",
    "               )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergence_thr = 80.0\n",
    "no_object_finetuned = no_object_df.loc[no_object_df[\"kl_divergence\"] <= kl_divergence_thr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(os.path.join(result_dir, \"no_objects_finetuned\")):\n",
    "    os.makedirs(os.path.join(result_dir, \"no_objects_finetuned\"))\n",
    "\n",
    "for idx, row in tqdm(no_object_finetuned.iterrows()):\n",
    "    panorama_id, cam_index, yaw_index = row[\"panorama_id\"], row[\"cam_index\"], row[\"yaw_index\"]\n",
    "    file_name = f\"{panorama_id}_i{cam_index}_{yaw_index}.jpg\"\n",
    "\n",
    "    file_prefix_path = os.path.join(color_images, file_name)\n",
    "    image = Image.open(file_prefix_path)\n",
    "\n",
    "    updated_path = os.path.join(result_dir, \"no_objects_finetuned\", file_name)\n",
    "    image = image.save(updated_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Save Metadata Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(os.path.join(metadata_dir, \"feature_metadata.csv\"), index=False)\n",
    "no_object_df.to_csv(os.path.join(metadata_dir, \"no_objects.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reconstruction-deep-network-Kqq14QZk-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
